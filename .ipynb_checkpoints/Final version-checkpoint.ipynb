{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b2cc20-d3b3-47ac-a275-bdc6373b4eac",
   "metadata": {},
   "source": [
    "# 1- Collect Images Using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ff5138-f88a-4097-978a-487fcf06368e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from opencv-contrib-python) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207693f4-43a6-4fb9-b35e-ffcf102c704d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03b7a22-f334-4067-9ffb-42081e4d0ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('data','images')\n",
    "number_images = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26488c4-049c-4540-83fd-5075e718a637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting image 5\n",
      "Collecting image 6\n",
      "Collecting image 7\n",
      "Collecting image 8\n",
      "Collecting image 9\n",
      "Collecting image 10\n",
      "Collecting image 11\n",
      "Collecting image 12\n",
      "Collecting image 13\n",
      "Collecting image 14\n",
      "Collecting image 15\n",
      "Collecting image 16\n",
      "Collecting image 17\n",
      "Collecting image 18\n",
      "Collecting image 19\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "for imgnum in range(number_images):\n",
    "    print('Collecting image {}'.format(imgnum))\n",
    "    ret, frame = cap.read()\n",
    "    imgname = os.path.join(IMAGES_PATH,f'{str(uuid.uuid1())}.jpg')\n",
    "    cv.imwrite(imgname, frame)\n",
    "    cv.imshow('frame', frame)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc887ee-71bd-404c-90f2-cce82c80aed4",
   "metadata": {},
   "source": [
    "# 2-Partition Unaugmented Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1607338c-97e2-4549-81c2-49630d4b78ba",
   "metadata": {},
   "source": [
    "### 2.1 SPLIT DATA INTO TRAIN TEST AND VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b90eeea-7c78-456b-a82c-4e3003a303bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import random\n",
    "\n",
    "class file_mover():\n",
    "    def __init__(self, destination_folder, source_folder = 'data/images/'):\n",
    "        self.source = source_folder\n",
    "        self.destination = destination_folder\n",
    "    \n",
    "    def for_loop(self, amount):\n",
    "        for _ in range(amount):\n",
    "              \n",
    "    # Choose a random file from the list\n",
    "            random_file = random.choice(os.listdir(self.source))\n",
    "\n",
    "    # Create the full paths for the source and destination files\n",
    "            source_file_path = os.path.join(self.source, random_file)\n",
    "            destination_file_path = os.path.join(self.destination, random_file)\n",
    "\n",
    "    # Move the file to the destination folder\n",
    "            shutil.move(source_file_path, destination_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c28fe3a2-58bd-4144-91bc-b35b3f899b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Train will be 63 images\n",
    "destination_folder = 'data/train/images'\n",
    "file_mover(destination_folder).for_loop(63)\n",
    "\n",
    "## Val will be 37\n",
    "destination_folder = 'data/val/images'\n",
    "file_mover(destination_folder).for_loop(37)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88970bc3-56d8-47ce-98e7-0dfda6244c67",
   "metadata": {},
   "source": [
    "### 2.2 Move the Matching Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e41e0f8-7e5e-4c8a-9be4-4493139ee872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for folder in ['train','test','val']:\n",
    "    for file in os.listdir(os.path.join('data', folder, 'images')):\n",
    "        \n",
    "        filename = file.split('.')[0]+'.json'\n",
    "        existing_filepath = os.path.join('data','labels', filename)\n",
    "        if os.path.exists(existing_filepath): \n",
    "            new_filepath = os.path.join('data',folder,'labels',filename)\n",
    "            os.replace(existing_filepath, new_filepath)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babc59c-1ebe-4a18-8bb0-8ff606335512",
   "metadata": {},
   "source": [
    "# 3- Apply Image Augmentation on Images and Labels using Albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac67eaed-4aa7-472d-b629-16685d356b65",
   "metadata": {},
   "source": [
    "### 3.1 Setup Albumentations Transform Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d89829d0-9bd9-4375-9532-2ddd8b66a0cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac7ba296-d374-4039-8c11-4e6adb8eec50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=720, height=720), \n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                       bbox_params=alb.BboxParams(format='albumentations', \n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9864103-5419-458a-bd7c-d7a31041bd32",
   "metadata": {},
   "source": [
    "### 3.2 Load a Test Image and Annotation with OpenCV and JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c95a1843-07c3-4098-8441-ac30c44e1e21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(os.path.join('data','train', 'images','0619d95e-cce1-11ee-989e-dca904778dc6.jpg'))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c54d0d3-d9ce-499b-8a17-f0b0e7f92c58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'train', 'labels', '0619d95e-cce1-11ee-989e-dca904778dc6.json'), 'r') as f:\n",
    "    label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af11b468-7867-41a6-93bd-5077bb894b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[254.8648648648649, 93.78378378378379], [824.2342342342342, 637.027027027027]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label['shapes'][0]['points']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da973497-6e84-433f-abff-8cfd53f4ed00",
   "metadata": {},
   "source": [
    "### 3.3 Extract Coordinates and Rescale to Match Image Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ee54cc-63bd-429a-b849-465886baccf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coords = [0,0,0,0]\n",
    "coords[0] = label['shapes'][0]['points'][0][0]\n",
    "coords[1] = label['shapes'][0]['points'][0][1]\n",
    "coords[2] = label['shapes'][0]['points'][1][0]\n",
    "coords[3] = label['shapes'][0]['points'][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a78c5047-a6d5-4722-a389-0709de7dc80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[254.8648648648649, 93.78378378378379, 824.2342342342342, 637.027027027027]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c720d51-b8b1-4b06-85f7-d6458e5a39ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coords = list(np.divide(coords, [1280,720,1280,720]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dbb9009-844f-4dc9-bae7-1aeb2964119e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1991131756756757,\n",
       " 0.13025525525525528,\n",
       " 0.6439329954954955,\n",
       " 0.8847597597597597]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51cb015-bd93-4897-b1c1-6258212f4f1e",
   "metadata": {},
   "source": [
    "### 3.4 Apply Augmentations and View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82a0826e-ffd9-4b7a-940a-98a48c339ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmented = augmentor(image=img, bboxes=[coords], class_labels=['person1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "232a1e5c-b67e-4913-a7e9-74b4b2ebfb8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[118, 127, 131],\n",
       "        [115, 124, 128],\n",
       "        [115, 126, 130],\n",
       "        ...,\n",
       "        [ 73,  76,  81],\n",
       "        [ 66,  69,  74],\n",
       "        [ 64,  67,  72]],\n",
       "\n",
       "       [[120, 129, 133],\n",
       "        [123, 132, 136],\n",
       "        [110, 121, 125],\n",
       "        ...,\n",
       "        [ 77,  80,  85],\n",
       "        [ 75,  78,  83],\n",
       "        [ 72,  75,  80]],\n",
       "\n",
       "       [[117, 126, 130],\n",
       "        [123, 132, 136],\n",
       "        [120, 131, 135],\n",
       "        ...,\n",
       "        [ 77,  80,  85],\n",
       "        [ 74,  77,  82],\n",
       "        [ 69,  72,  77]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 17,  21,  32],\n",
       "        [ 12,  18,  29],\n",
       "        [ 13,  19,  30],\n",
       "        ...,\n",
       "        [ 12,  15,  20],\n",
       "        [ 12,  14,  22],\n",
       "        [ 12,  14,  22]],\n",
       "\n",
       "       [[ 17,  21,  32],\n",
       "        [ 15,  21,  32],\n",
       "        [ 14,  20,  31],\n",
       "        ...,\n",
       "        [ 12,  15,  20],\n",
       "        [ 12,  14,  22],\n",
       "        [ 12,  14,  22]],\n",
       "\n",
       "       [[ 12,  16,  27],\n",
       "        [ 11,  17,  28],\n",
       "        [ 10,  16,  27],\n",
       "        ...,\n",
       "        [ 12,  15,  20],\n",
       "        [ 12,  14,  22],\n",
       "        [ 12,  14,  22]]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f485b69-31af-40dc-8310-c8137b8f5513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.13025525525525528, 0.7031031031031031, 0.8847597597597597)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented['bboxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eac4c9-3088-4e27-b350-d15ac18c00d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv2.rectangle(augmented['image'], \n",
    "              tuple(np.multiply(augmented['bboxes'][0][:2], [700,700]).astype(int)),\n",
    "              tuple(np.multiply(augmented['bboxes'][0][2:], [700,700]).astype(int)), \n",
    "                    (255,0,0), 2)\n",
    "\n",
    "plt.imshow(augmented['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae1851-b90e-4d17-ad27-f20b35b00b94",
   "metadata": {},
   "source": [
    "# 4- Build and Run Augmentation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc0017b-4beb-4241-b667-ff897b9eab2d",
   "metadata": {},
   "source": [
    "### 4.1 Run Augmentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6e1e07f-4129-43c0-b8dc-a5a1c7ab0e67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image must be numpy array type\n",
      "x_max is less than or equal to x_min for bbox [0.2575309684684685, 0.9773523523523522, 0.0, 0.449659468733038, 'face'].\n",
      "image must be numpy array type\n"
     ]
    }
   ],
   "source": [
    "for partition in ['test','train','val']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            coords[0] = label['shapes'][0]['points'][0][0]\n",
    "            coords[1] = label['shapes'][0]['points'][0][1]\n",
    "            coords[2] = label['shapes'][0]['points'][1][0]\n",
    "            coords[3] = label['shapes'][0]['points'][1][1]\n",
    "            coords = list(np.divide(coords, [1280,720,1280,720]))\n",
    "\n",
    "        try: \n",
    "            for x in range(30):\n",
    "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = augmented['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "\n",
    "\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a86b1-e82a-4157-8bac-157ddc3bd2da",
   "metadata": {},
   "source": [
    "### 4.2 Load a Test Image and Annotation with OpenCV and JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d382e0-9332-480b-921c-2ace59ff1e24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(os.path.join('data','train', 'images','0619d95e-cce1-11ee-989e-dca904778dc6.jpg'))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d73384e-941e-4b34-b242-9a3b51cf9c17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'train', 'labels', '0619d95e-cce1-11ee-989e-dca904778dc6.json'), 'r') as f:\n",
    "    label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1af43ad-1ab7-4872-bad1-152ee05acbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[254.8648648648649, 93.78378378378379], [824.2342342342342, 637.027027027027]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label['shapes'][0]['points']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437dfd83-03d5-493e-a433-0ada0a693b24",
   "metadata": {},
   "source": [
    "### 4.3 Extract Coordinates and Rescale to Match Image Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "095417d9-b8d5-4c92-97e1-941c118f365e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coords = [0,0,0,0]\n",
    "coords[0] = label['shapes'][0]['points'][0][0]\n",
    "coords[1] = label['shapes'][0]['points'][0][1]\n",
    "coords[2] = label['shapes'][0]['points'][1][0]\n",
    "coords[3] = label['shapes'][0]['points'][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7780cdb2-bab1-4154-baaa-762e75670a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[254.8648648648649, 93.78378378378379, 824.2342342342342, 637.027027027027]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "804cd008-8c13-4b54-ae3d-2fd21434a9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coords = list(np.divide(coords, [1280,720,1280,720]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3512ee84-0eab-4030-9968-5ca0454581a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1991131756756757,\n",
       " 0.13025525525525528,\n",
       " 0.6439329954954955,\n",
       " 0.8847597597597597]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214c2654-a33a-4bc4-9cff-842e4c2e9518",
   "metadata": {},
   "source": [
    "### 4.4 Apply Augmentations and View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8ca15a1-f44c-405d-a2c2-d61ae7181f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmented = augmentor(image=img, bboxes=[coords], class_labels=['person1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9078981d-19e1-4925-96a3-783b54b93303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[118, 127, 131],\n",
       "        [115, 124, 128],\n",
       "        [115, 126, 130],\n",
       "        ...,\n",
       "        [ 73,  76,  81],\n",
       "        [ 66,  69,  74],\n",
       "        [ 64,  67,  72]],\n",
       "\n",
       "       [[120, 129, 133],\n",
       "        [123, 132, 136],\n",
       "        [110, 121, 125],\n",
       "        ...,\n",
       "        [ 77,  80,  85],\n",
       "        [ 75,  78,  83],\n",
       "        [ 72,  75,  80]],\n",
       "\n",
       "       [[117, 126, 130],\n",
       "        [123, 132, 136],\n",
       "        [120, 131, 135],\n",
       "        ...,\n",
       "        [ 77,  80,  85],\n",
       "        [ 74,  77,  82],\n",
       "        [ 69,  72,  77]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 17,  21,  32],\n",
       "        [ 12,  18,  29],\n",
       "        [ 13,  19,  30],\n",
       "        ...,\n",
       "        [ 12,  15,  20],\n",
       "        [ 12,  14,  22],\n",
       "        [ 12,  14,  22]],\n",
       "\n",
       "       [[ 17,  21,  32],\n",
       "        [ 15,  21,  32],\n",
       "        [ 14,  20,  31],\n",
       "        ...,\n",
       "        [ 12,  15,  20],\n",
       "        [ 12,  14,  22],\n",
       "        [ 12,  14,  22]],\n",
       "\n",
       "       [[ 12,  16,  27],\n",
       "        [ 11,  17,  28],\n",
       "        [ 10,  16,  27],\n",
       "        ...,\n",
       "        [ 12,  15,  20],\n",
       "        [ 12,  14,  22],\n",
       "        [ 12,  14,  22]]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f684a814-bb31-4874-8866-1b94a1f1c2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.13025525525525528, 0.7031031031031031, 0.8847597597597597)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented['bboxes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a151e0-fa51-40d1-8f86-91ee6019b8e7",
   "metadata": {},
   "source": [
    "# 5. Setup and Create Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caeade4d-9aab-436b-a45f-3f40e0cb971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_folder, label_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.label_folder = label_folder\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images = sorted(os.listdir(image_folder))\n",
    "        self.labels = sorted(file for file in os.listdir(label_folder) if file.endswith('.json'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_folder, self.images[idx])\n",
    "\n",
    "        # Get the corresponding label file in the label folder\n",
    "        label_file = self.labels[idx]\n",
    "        label_path = os.path.join(self.label_folder, label_file)\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Open and read the content of the label file\n",
    "        with open(label_path, 'r') as f:\n",
    "            # Load JSON content from the label file\n",
    "            label_data = json.load(f)\n",
    "\n",
    "        # Convert label data to tensor\n",
    "        # Assuming your label_data contains 'class' and 'bboxes'\n",
    "        label_tensor = torch.tensor([label_data['class']] + label_data['bbox'], dtype=torch.float32)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label_tensor\n",
    "\n",
    "# Define your transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((120, 120)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(image_folder='aug_data/train/images', label_folder='aug_data/train/labels', transform=transform)\n",
    "val_dataset = CustomDataset(image_folder='aug_data/val/images', label_folder='aug_data/val/labels/', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce20255-5cad-4b28-84c5-b932901b5184",
   "metadata": {},
   "source": [
    "# 2- Create the CNN using Batch-Norm and Max-Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d20a4e4-4200-4f2f-8795-473d115aa1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm4 = nn.BatchNorm2d(128)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 5)  # Assuming 6 parameters for bounding box + class\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.batch_norm1(nn.functional.relu(self.conv1(x))))\n",
    "        x = self.pool2(self.batch_norm2(nn.functional.relu(self.conv2(x))))\n",
    "        x = self.pool3(self.batch_norm3(nn.functional.relu(self.conv3(x))))\n",
    "        x = self.pool4(self.batch_norm4(nn.functional.relu(self.conv4(x))))\n",
    "\n",
    "        x = x.view(-1, 128 * 7 * 7)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaad07e-c89d-4d66-9360-c2c69e9cb315",
   "metadata": {},
   "source": [
    "# 3- Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba787cf0-bd65-4bba-b578-16d7149982aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.027534882786373296, Validation Loss: 0.0961288046091795\n",
      "Epoch 2/5, Train Loss: 0.02533046609411637, Validation Loss: 0.03846120914178235\n",
      "Epoch 3/5, Train Loss: 0.017338657813767592, Validation Loss: 0.02882645691611937\n",
      "Epoch 4/5, Train Loss: 0.012750950704018275, Validation Loss: 0.025986706971057823\n",
      "Epoch 5/5, Train Loss: 0.010920316081804533, Validation Loss: 0.025309070013463497\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs=5, learning_rate=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss = criterion(outputs, labels)\n",
    "                epoch_val_loss += val_loss.item()\n",
    "\n",
    "        # Average loss over all batches in an epoch\n",
    "        epoch_train_loss /= len(train_loader)\n",
    "        epoch_val_loss /= len(val_loader)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_train_loss}, Validation Loss: {epoch_val_loss}')\n",
    "\n",
    "        # Save losses for plotting\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "\n",
    "    return train_losses, val_losses\n",
    "    \n",
    "train_losses, val_losses = train(model, train_loader, val_loader, num_epochs=5, learning_rate=0.001)\n",
    "\n",
    "model_path = 'Models/model_CNN.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dab15e-7049-4fef-a0d1-1e145fe5cb1b",
   "metadata": {},
   "source": [
    "# 4- Plot the Training Loss x Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b2e0716-33e8-4716-928a-06100de2dc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(train_losses, val_losses):\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_loss(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9839ab-0b43-4f55-add3-f262b1f2c609",
   "metadata": {},
   "source": [
    "# 5 - Create OpenCV Detection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702e2517-6205-41c1-98f7-0009d7163ec7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleCNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleCNN\u001b[49m()\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModels/model_CNN.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SimpleCNN' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load the trained model\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load('Models/model_CNN.pth'))\n",
    "model.eval()\n",
    "\n",
    "def detect_face(frame, model):\n",
    "    # Preprocess the frame\n",
    "    img = cv2.resize(frame, (120, 120))\n",
    "    img = Image.fromarray(img)  # Convert numpy array to PIL Image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # Add any other necessary transformations\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Run the model\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        \n",
    "\n",
    "    # Post-process the output (assuming bounding box coordinates and class)\n",
    "    # Extract class and bounding box coordinates from the output tensor\n",
    "    pred_class = int(output[0, 0])\n",
    "    bbox = list(map(float, output[0, 1:].tolist()))\n",
    "    print(bbox[3])\n",
    "    print(pred_class)\n",
    "    \n",
    "\n",
    "    # Draw bounding box only if the predicted class is 0\n",
    "    if pred_class == 0:\n",
    "        print(f\"Class: {pred_class}, Bbox: {bbox}\")\n",
    "    \n",
    "        bbox = [int(coord * frame.shape[1]) for coord in bbox]  # Scale coordinates\n",
    "\n",
    "        cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Open a webcam\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect face\n",
    "    frame = detect_face(frame, model)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Press 'Esc' to exit\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eabf65b-8a19-4a77-a446-50534002b946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
